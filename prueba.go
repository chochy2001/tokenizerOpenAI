// This is a simple Go program that demonstrates how to use the `go/token` package
package main

func textToTokenize() string {
	text := `Example text to tokenize. This is a simple example of a string that will be tokenized. It contains various words and punctuation marks, which will be processed by the tokenizer. The goal is to demonstrate how the tokenizer works and how it can be used to break down text into smaller components. This is useful for natural language processing tasks, such as sentiment analysis, text classification, and more. The tokenizer will take this string and convert it into a list of tokens, which can then be used for further analysis or processing.`

	return text
}
