# OpenAI Tokenizer en Go

Este proyecto proporciona una utilidad para tokenizar texto utilizando el tokenizador de OpenAI implementado en Go. La tokenizaci贸n es un proceso fundamental en el procesamiento de lenguaje natural (NLP) que divide el texto en unidades m谩s peque帽as llamadas tokens, lo que resulta 煤til para:

- Calcular l铆mites de tokens para APIs de modelos de lenguaje como GPT
- Optimizar el uso de recursos en aplicaciones de NLP
- Preparar texto para an谩lisis y procesamiento avanzado

##  Estructura del Proyecto

El proyecto tiene la siguiente estructura:

```
.
 go.mod          # Define las dependencias del proyecto
 go.sum          # Checksums de las dependencias
 main.go         # C贸digo principal con la l贸gica de tokenizaci贸n
 prueba.go       # Contiene el texto de ejemplo para tokenizar
```

##  Requisitos

- Go 1.18 o superior (desarrollado con Go 1.22.2)
- Dependencias gestionadas autom谩ticamente con Go Modules

##  Dependencias

El proyecto utiliza las siguientes bibliotecas:

- `github.com/pkoukk/tiktoken-go v0.1.7`: Implementaci贸n en Go del tokenizador tiktoken de OpenAI
- `github.com/dlclark/regexp2 v1.10.0`: Biblioteca de expresiones regulares avanzadas
- `github.com/google/uuid v1.3.0`: Generaci贸n de identificadores 煤nicos

##  Instalaci贸n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/tokenizerGoOpenAI.git
cd tokenizerGoOpenAI

# Instalar dependencias
go mod download
```

##  Uso

### Ejecuci贸n B谩sica

Para ejecutar el tokenizador con el texto de ejemplo predefinido:

```bash
go run main.go prueba.go
```

El programa mostrar谩 el n煤mero total de tokens en el texto proporcionado.

### Personalizaci贸n del Texto

Puedes modificar la funci贸n `textToTokenize()` en el archivo `prueba.go` para cambiar el texto que deseas tokenizar:

```go
func textToTokenize() string {
    // Reemplaza este texto con el que deseas tokenizar
    text := `Tu texto aqu铆...`
    return text
}
```

### Integraci贸n en tu Propio C贸digo

Para usar esta funcionalidad en tu proyecto:

```go
package main

import (
    "fmt"
    "github.com/pkoukk/tiktoken-go"
)

func main() {
    // Selecciona el modelo de codificaci贸n (cl100k_base es usado por GPT-4, GPT-3.5-Turbo)
    encoding := "cl100k_base"
    
    // Inicializa el codificador
    tke, err := tiktoken.GetEncoding(encoding)
    if err != nil {
        fmt.Printf("Error al obtener la codificaci贸n: %v\n", err)
        return
    }
    
    // Tu texto para tokenizar
    text := "Este es un ejemplo de texto para tokenizar."
    
    // Codifica el texto en tokens
    tokens := tke.Encode(text, nil, nil)
    
    // Muestra el resultado
    fmt.Printf("N煤mero total de tokens: %d\n", len(tokens))
    
    // Para ver los tokens individuales (opcional)
    fmt.Println("Tokens:", tokens)
}
```

##  Modelos de Tokenizaci贸n Disponibles

La biblioteca `tiktoken-go` soporta varios modelos de tokenizaci贸n de OpenAI:

- `cl100k_base`: Usado por GPT-4 y GPT-3.5-Turbo
- `p50k_base`: Usado por modelos GPT-3 de texto (Davinci, Curie, etc.)
- `r50k_base`: Usado por modelos anteriores de GPT-3
- Y otros modelos de codificaci贸n soportados por la biblioteca

##  Modo Sin Conexi贸n

Si prefieres no descargar el diccionario en tiempo de ejecuci贸n, puedes usar el cargador sin conexi贸n:

```go
import (
    "github.com/pkoukk/tiktoken-go"
    "github.com/pkoukk/tiktoken-go/loader"
)

func main() {
    // Configura el cargador sin conexi贸n
    tiktoken.SetBpeLoader(loader.NewOfflineLoader())
    
    // Contin煤a con la codificaci贸n como se mostr贸 anteriormente
    // ...
}
```

## И Ejemplos Adicionales

### Decodificaci贸n de Tokens a Texto

```go
// Codifica el texto en tokens
text := "Ejemplo de decodificaci贸n"
tokens := tke.Encode(text, nil, nil)

// Decodifica los tokens de vuelta a texto
decodedText := tke.Decode(tokens)
fmt.Println("Texto decodificado:", string(decodedText))
```

### Conteo de Tokens para APIs de OpenAI

```go
func estimateTokenCount(text string) int {
    encoding := "cl100k_base"
    tke, _ := tiktoken.GetEncoding(encoding)
    return len(tke.Encode(text, nil, nil))
}

// Ejemplo de uso
prompt := "Explica c贸mo funciona la tokenizaci贸n de texto."
tokenCount := estimateTokenCount(prompt)
fmt.Printf("Este prompt utilizar谩 aproximadamente %d tokens\n", tokenCount)
```

##  Nota sobre la Precisi贸n

El conteo de tokens puede variar ligeramente entre diferentes implementaciones de tokenizadores. Esta implementaci贸n en Go intenta ser lo m谩s fiel posible al tokenizador oficial de OpenAI.

##  Contribuciones

Las contribuciones son bienvenidas. Si encuentras alg煤n problema o tienes alguna sugerencia, por favor crea un issue o env铆a un pull request.

##  Licencia

Este proyecto est谩 bajo la licencia MIT. Consulta el archivo LICENSE para m谩s detalles.

---

Creado por [Jorge Salgado Miranda] - [2025]
